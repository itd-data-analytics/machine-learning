{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "import imageio\n",
    "from skimage import data, io, filters\n",
    "from matplotlib import pyplot as plt\n",
    "from random import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sqlite3\n",
    "from training import image_training as it\n",
    "import os\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6064\n",
      "('..\\\\..\\\\images\\\\100000000001.jpg', 1)\n",
      "9156\n",
      "('..\\\\..\\\\images\\\\100000005221.jpg', 0)\n"
     ]
    }
   ],
   "source": [
    "classified_true = it.get_true_images('guardrail')\n",
    "print(len(classified_true))\n",
    "print(classified_true[0])\n",
    "\n",
    "classified_false = it.get_false_images('guardrail')\n",
    "print(len(classified_false))\n",
    "print(classified_false[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Test List and Classified List together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12127\n"
     ]
    }
   ],
   "source": [
    "lt = [classified_false[0:len(classified_true)-1], classified_true]\n",
    "\n",
    "flattened_list = [i for s in lt for i in s]\n",
    "\n",
    "#print (flattened_list)\n",
    "print(len(flattened_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('..\\\\..\\\\images\\\\105010304051.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100004407111.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\106001405201.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\108011207021.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\203005241021.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\113002420081.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\105003717071.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\203001917051.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100000404091.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\105014224241.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\101010856201.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\104001712081.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100004709221.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100005237271.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100000431171.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000243011.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\108010940091.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000113141.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\203001855231.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\104005944181.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\107014501161.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\105014220281.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\104002815231.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\107000523041.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100001017011.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100001151181.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100001011081.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\325005808162.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\107014531211.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\110004200251.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\103002507121.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\202011046111.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\107015543221.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\109000716131.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\108012907201.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100001211001.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000140091.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\111010649001.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\110005400011.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\205005026271.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\106005523271.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000124271.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\106010001101.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\102011329281.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100005244231.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\205005024121.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\202010741121.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\113003716091.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100000648021.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\108010131111.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\108012826091.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\109000415061.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100001014241.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\102010554271.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\113014029181.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\105005906231.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\107014525151.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100001214291.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000116081.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\105002528101.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\105005435111.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\103002406261.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\203013218061.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100000734211.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\106013056041.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\103000934101.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000313151.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000410031.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\109005318061.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\202011012181.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\111004747291.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\108012021161.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100001008011.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\200005423261.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\102002032121.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000735111.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\109001326271.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\108012900101.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\105014244041.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\200005345061.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100001225041.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000727161.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\112004436081.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\201004837191.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\203001914131.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100000840291.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100001008251.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\203014701041.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100001213181.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\108012847041.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\101001515041.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\107014926141.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\107015427181.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100000419111.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\100000059021.jpg', 0)\n",
      "('..\\\\..\\\\images\\\\205003845211.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\203001905001.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\103002416071.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\100005231161.jpg', 1)\n",
      "('..\\\\..\\\\images\\\\106005457111.jpg', 0)\n"
     ]
    }
   ],
   "source": [
    "shuffle(flattened_list)\n",
    "for i in flattened_list[0:100]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Validate That The Filepaths Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS: ALL FILES OKAY\n"
     ]
    }
   ],
   "source": [
    "for file in flattened_list:\n",
    "    if not os.path.isfile(file[0]):\n",
    "        raise RuntimeError('File: {} could not be located.'.format(file[0]))\n",
    "print('STATUS: ALL FILES OKAY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Bar Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBar(object):\n",
    "    \n",
    "    def __init__(self, total_count, step_count=50):\n",
    "        \"\"\"Initialze a progress bar\n",
    "        \n",
    "        Keyword Arguments:\n",
    "        total_count -- The total count to track progress.\n",
    "        step_count -- The number of steps in this total count.\n",
    "        \"\"\"\n",
    "        self.total_count = total_count\n",
    "        self.step_count = step_count\n",
    "        self.step_size = int(self.total_count / self.step_count)\n",
    "        self.step = 0\n",
    "        self.value = 0\n",
    "        \n",
    "    def __str__(self):\n",
    "        string = 'Progress |'\n",
    "        for i in range(0, self.step_count):\n",
    "            if i < self.step:\n",
    "                string += '#'\n",
    "            else:\n",
    "                string += '-'\n",
    "        string += '| {:.2f}%'.format((float(self.value) / self.total_count) * 100)\n",
    "        return string\n",
    "        \n",
    "    def update(self, value):\n",
    "        self.value = value\n",
    "        self.step = int(self.value / self.step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Files And Open Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'data.pickled'\n",
    "answersfile = 'answers.pickled'\n",
    "\n",
    "datapickled = open(datafile, 'wb+')\n",
    "answerspickled = open(answersfile, 'wb+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Data To Files And Close Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress |--------------------------------------------------| 0.00% \n",
      "Progress |#################################-----------------| 67.11%\r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "progressbar = ProgressBar(len(flattened_list))\n",
    "item_count = 0\n",
    "print(progressbar, '\\r')\n",
    "for item in flattened_list:\n",
    "    item_count += 1\n",
    "    try:\n",
    "        data_array = np.array(imageio.imread(item[0]))\n",
    "        string = pickle.dumps(data_array)\n",
    "        pickle.dump(string, datapickled)\n",
    "        pickle.dump(item[1], answerspickled)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(item)\n",
    "        break\n",
    "    \n",
    "    progressbar.update(item_count)\n",
    "    print(progressbar, end='\\r')\n",
    "\n",
    "datapickled.close()\n",
    "answerspickled.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(warm_start=True, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function To Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(start_index, end_index):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    with open(datafile, 'rb') as datapickled:\n",
    "        for i in range(0, start_index):\n",
    "            pickle.load(datapickled)\n",
    "        for i in range(start_index, end_index):\n",
    "            string = pickle.load(datapickled)\n",
    "            X.append(pickle.loads(string))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    with open(answersfile, 'rb') as answerspickled:\n",
    "        for i in range(0, start_index):\n",
    "            pickle.load(answerspickled)\n",
    "        for i in range(start_index, end_index):\n",
    "            y.append(pickle.load(answerspickled))\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X = X.reshape(X.shape[1] * X.shape[2] * X.shape[3], X.shape[0]).T\n",
    "    y = y.reshape(y.shape[0],)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf.set_params(n_estimators=clf.get_params()['n_estimators'] + 100)\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train The Model Incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "progressbar = ProgressBar(len(flattened_list))\n",
    "print(progressbar, end='\\r')\n",
    "for i in range(100, len(flattened_list), 100):\n",
    "    X_train, X_test, y_train, y_test = train_classifier(i-100, i)\n",
    "    progressbar.update(i)\n",
    "    print(progressbar, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test The Model Based On Prediction Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test,preds))\n",
    "print (X_test.shape)\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt To Save The Machine To A File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machinefile = 'machine.pickled'\n",
    "with open(machinefile, 'wb') as machinepickled:\n",
    "    pickle.dump(clf, machinepickled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '301004459215'\n",
    "# '301004457041'\n",
    "# '301004457092'\n",
    "# '301004457251'\n",
    "\n",
    "#  '301004400151' (yes example)\n",
    "#  '301004405171' (no example)\n",
    "\n",
    "yes = '301004400151.jpg'\n",
    "no = '301004405171.jpg'\n",
    "\n",
    "directory = '//itdd03fsp01/videolog/301/44/' + no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(dir):\n",
    "    data_array = np.array(imageio.imread(dir))\n",
    "    reshape_array = data_array.reshape(data_array.shape[0] * data_array.shape[1] * data_array.shape[2], 1).T\n",
    "    return reshape_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = transform_image(directory)\n",
    "print (test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(test_image)\n",
    "if prediction == 1:\n",
    "    print('Yes')\n",
    "elif prediction == 0:\n",
    "    print('No')\n",
    "else:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
